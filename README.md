# AWRQ: Activation-aware Weight Reformulation Quantization for Large Language Models
___

